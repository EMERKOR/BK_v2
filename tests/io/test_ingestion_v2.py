"""
Integration tests for Ball Knower v2 Phase 2 ingestion.

Tests the complete ingestion pipeline:
1. Raw CSV → Clean tables (Stream A)
2. Clean tables → game_state_v2
3. Schema validation
4. Primary key uniqueness
5. File output and logging
"""
from __future__ import annotations

import json
from pathlib import Path

import pandas as pd
import pytest

from ball_knower.io.clean_tables import (
    build_schedule_games_clean,
    build_final_scores_clean,
    build_market_lines_spread_clean,
    build_market_lines_total_clean,
    build_market_moneyline_clean,
)
from ball_knower.game_state.game_state_v2 import build_game_state_v2, load_game_state_v2
from ball_knower.io.schemas_v2 import ALL_SCHEMAS


# ========== Fixtures ==========


@pytest.fixture
def fixture_data_dir(tmp_path):
    """
    Create a minimal fixture dataset for testing.

    Creates RAW_schedule, RAW_scores, and RAW_market files for season 2025, week 11.
    """
    season = 2025
    week = 11

    # Create directory structure
    schedule_dir = tmp_path / "RAW_schedule" / str(season)
    scores_dir = tmp_path / "RAW_scores" / str(season)
    spread_dir = tmp_path / "RAW_market" / "spread" / str(season)
    total_dir = tmp_path / "RAW_market" / "total" / str(season)
    moneyline_dir = tmp_path / "RAW_market" / "moneyline" / str(season)

    for d in [schedule_dir, scores_dir, spread_dir, total_dir, moneyline_dir]:
        d.mkdir(parents=True, exist_ok=True)

    # Create schedule CSV with 2 games
    # Note: game_id will be generated by the builder as {season}_{week}_{away}_{home}
    schedule_df = pd.DataFrame({
        "teams": ["BUF@KC", "SF@DAL"],
        "kickoff": ["2025-11-17T18:00:00Z", "2025-11-17T21:00:00Z"],
        "stadium": ["Arrowhead Stadium", "AT&T Stadium"],
    })
    schedule_df.to_csv(schedule_dir / f"schedule_week_{week:02d}.csv", index=False)

    # Create scores CSV
    scores_df = pd.DataFrame({
        "teams": ["BUF@KC", "SF@DAL"],
        "home_score": [24, 28],
        "away_score": [21, 17],
    })
    scores_df.to_csv(scores_dir / f"scores_week_{week:02d}.csv", index=False)

    # Create spread CSV
    spread_df = pd.DataFrame({
        "teams": ["BUF@KC", "SF@DAL"],
        "market_closing_spread": [-3.5, -7.0],
    })
    spread_df.to_csv(spread_dir / f"spread_week_{week:02d}.csv", index=False)

    # Create total CSV
    total_df = pd.DataFrame({
        "teams": ["BUF@KC", "SF@DAL"],
        "market_closing_total": [47.5, 45.0],
    })
    total_df.to_csv(total_dir / f"total_week_{week:02d}.csv", index=False)

    # Create moneyline CSV
    moneyline_df = pd.DataFrame({
        "teams": ["BUF@KC", "SF@DAL"],
        "market_moneyline_home": [-150, -280],
        "market_moneyline_away": [130, 220],
    })
    moneyline_df.to_csv(moneyline_dir / f"moneyline_week_{week:02d}.csv", index=False)

    return tmp_path


# ========== Schema Tests ==========


def test_schedule_games_clean_schema(fixture_data_dir):
    """Test that schedule_games_clean matches its schema."""
    df = build_schedule_games_clean(2025, 11, data_dir=fixture_data_dir)

    schema = ALL_SCHEMAS["schedule_games_clean"]

    # Check all schema columns are present
    for col in schema.columns:
        if col in schema.required:
            assert col in df.columns, f"Required column '{col}' missing"

    # Check dtypes (basic type family check)
    assert pd.api.types.is_integer_dtype(df["season"])
    assert pd.api.types.is_integer_dtype(df["week"])
    assert df["home_team"].dtype == object  # string
    assert df["away_team"].dtype == object  # string


def test_final_scores_clean_schema(fixture_data_dir):
    """Test that final_scores_clean matches its schema."""
    df = build_final_scores_clean(2025, 11, data_dir=fixture_data_dir)

    schema = ALL_SCHEMAS["final_scores_clean"]

    # Check required columns
    for col in schema.required:
        assert col in df.columns, f"Required column '{col}' missing"

    # Check numeric scores
    assert pd.api.types.is_integer_dtype(df["home_score"])
    assert pd.api.types.is_integer_dtype(df["away_score"])


# ========== Primary Key Tests ==========


def test_schedule_no_duplicate_game_ids(fixture_data_dir):
    """Test that schedule has no duplicate game_ids."""
    df = build_schedule_games_clean(2025, 11, data_dir=fixture_data_dir)

    duplicates = df["game_id"].duplicated()
    assert not duplicates.any(), f"Found duplicate game_ids: {df[duplicates]['game_id'].tolist()}"


def test_final_scores_no_duplicate_game_ids(fixture_data_dir):
    """Test that final_scores has no duplicate game_ids."""
    df = build_final_scores_clean(2025, 11, data_dir=fixture_data_dir)

    duplicates = df["game_id"].duplicated()
    assert not duplicates.any(), f"Found duplicate game_ids"


# ========== Row Count Consistency Tests ==========


def test_schedule_and_scores_same_row_count(fixture_data_dir):
    """Test that schedule and scores have the same number of games."""
    schedule_df = build_schedule_games_clean(2025, 11, data_dir=fixture_data_dir)
    scores_df = build_final_scores_clean(2025, 11, data_dir=fixture_data_dir)

    assert len(schedule_df) == len(scores_df), \
        f"Schedule has {len(schedule_df)} games, scores has {len(scores_df)}"


# ========== Team Mapping Tests ==========


def test_schedule_normalizes_team_codes(fixture_data_dir):
    """Test that team codes are normalized to canonical BK codes."""
    df = build_schedule_games_clean(2025, 11, data_dir=fixture_data_dir)

    # All teams should be canonical BK codes
    from ball_knower.mappings import CANONICAL_TEAM_CODES

    for team in df["home_team"]:
        assert team in CANONICAL_TEAM_CODES, f"Invalid home_team code: {team}"

    for team in df["away_team"]:
        assert team in CANONICAL_TEAM_CODES, f"Invalid away_team code: {team}"


# ========== File Output Tests ==========


def test_schedule_writes_parquet(fixture_data_dir):
    """Test that schedule_games_clean writes Parquet file."""
    build_schedule_games_clean(2025, 11, data_dir=fixture_data_dir)

    parquet_path = fixture_data_dir / "clean" / "schedule_games_clean" / "2025" / "schedule_games_clean_2025_week_11.parquet"
    assert parquet_path.exists(), f"Parquet file not written to {parquet_path}"

    # Verify it can be read
    df_read = pd.read_parquet(parquet_path)
    assert len(df_read) > 0


def test_schedule_emits_log(fixture_data_dir):
    """Test that schedule_games_clean emits JSON log."""
    build_schedule_games_clean(2025, 11, data_dir=fixture_data_dir)

    log_path = fixture_data_dir / "clean" / "_logs" / "schedule_games_clean" / "2025_week_11.json"
    assert log_path.exists(), f"Log file not written to {log_path}"

    # Verify log content
    with open(log_path) as f:
        log_data = json.load(f)

    assert log_data["table_name"] == "schedule_games_clean"
    assert log_data["season"] == 2025
    assert log_data["week"] == 11
    assert "row_count_raw" in log_data
    assert "row_count_clean" in log_data
    assert "ingested_at_utc" in log_data


# ========== game_state_v2 Integration Tests ==========


def test_build_game_state_v2_end_to_end(fixture_data_dir):
    """End-to-end test: build game_state_v2 from fixtures."""
    df = build_game_state_v2(2025, 11, data_dir=fixture_data_dir)

    # Should have 2 games
    assert len(df) == 2

    # Check required columns
    schema = ALL_SCHEMAS["game_state_v2"]
    for col in schema.required:
        assert col in df.columns, f"Required column '{col}' missing"

    # Check game_ids match expected
    game_ids = set(df["game_id"])
    # game_id is generated as {season}_{week}_{away}_{home}
    # BUF@KC -> 2025_11_BUF_KC
    # SF@DAL -> 2025_11_SF_DAL
    expected_game_ids = {"2025_11_BUF_KC", "2025_11_SF_DAL"}
    assert game_ids == expected_game_ids, f"Game IDs mismatch. Got: {game_ids}, Expected: {expected_game_ids}"

    # Check that scores are populated
    assert (df["home_score"] == 24).any()
    assert (df["home_score"] == 28).any()

    # Check that markets are populated
    assert (df["market_closing_spread"] == -3.5).any()
    assert (df["market_closing_total"] == 47.5).any()

    # Check team codes are canonical
    from ball_knower.mappings import CANONICAL_TEAM_CODES
    for team in df["home_team"]:
        assert team in CANONICAL_TEAM_CODES

    for team in df["away_team"]:
        assert team in CANONICAL_TEAM_CODES


def test_game_state_v2_writes_parquet(fixture_data_dir):
    """Test that game_state_v2 writes Parquet file."""
    build_game_state_v2(2025, 11, data_dir=fixture_data_dir)

    parquet_path = fixture_data_dir / "clean" / "game_state_v2" / "2025" / "game_state_v2_2025_week_11.parquet"
    assert parquet_path.exists(), f"game_state_v2 Parquet not written"

    # Verify it can be loaded via load_game_state_v2
    df_loaded = load_game_state_v2(2025, 11, data_dir=fixture_data_dir)
    assert len(df_loaded) == 2


def test_game_state_v2_emits_log(fixture_data_dir):
    """Test that game_state_v2 emits comprehensive JSON log."""
    build_game_state_v2(2025, 11, data_dir=fixture_data_dir)

    log_path = fixture_data_dir / "clean" / "_logs" / "game_state_v2" / "2025_week_11.json"
    assert log_path.exists()

    with open(log_path) as f:
        log_data = json.load(f)

    assert log_data["table_name"] == "game_state_v2"
    assert log_data["season"] == 2025
    assert log_data["week"] == 11
    assert log_data["row_count"] == 2
    assert "source_tables" in log_data
    assert "schedule_games_clean" in log_data["source_tables"]
    assert "games_with_scores" in log_data
    assert "games_with_spread" in log_data
    assert "ingested_at_utc" in log_data


def test_load_game_state_v2_raises_on_missing(tmp_path):
    """Test that load_game_state_v2 raises error for non-existent data."""
    with pytest.raises(FileNotFoundError) as exc_info:
        load_game_state_v2(2099, 99, data_dir=tmp_path)

    assert "game_state_v2 not found" in str(exc_info.value)
    assert "2099" in str(exc_info.value)
    assert "99" in str(exc_info.value)


# ========== Value Validation Tests ==========


def test_market_values_are_numeric(fixture_data_dir):
    """Test that market values are properly converted to numeric."""
    df = build_game_state_v2(2025, 11, data_dir=fixture_data_dir)

    # Check dtypes (numeric includes both float and int)
    assert pd.api.types.is_numeric_dtype(df["market_closing_spread"])
    assert pd.api.types.is_numeric_dtype(df["market_closing_total"])
    assert pd.api.types.is_numeric_dtype(df["market_moneyline_home"])
    assert pd.api.types.is_numeric_dtype(df["market_moneyline_away"])

    # Check specific values
    kc_game = df[df["home_team"] == "KC"].iloc[0]
    assert kc_game["market_closing_spread"] == -3.5
    assert kc_game["market_closing_total"] == 47.5
    assert kc_game["market_moneyline_home"] == -150.0
    assert kc_game["market_moneyline_away"] == 130.0
